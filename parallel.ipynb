{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2734eaf-edc1-44d5-a77f-e81c41822e21",
   "metadata": {},
   "source": [
    "# Parallelizing operations using Multithreading, Multiprocessing and Distributed processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f9c61-a26e-4bb5-9b27-3bf60a3e7b4c",
   "metadata": {},
   "source": [
    "Multithreading, Multiprocessing and Distributed processing are three common methods to parallelize your workloads to reduce the execution. Imagine a scenario where you've to train thousands of ML models or inference a model for thousands of records. Writing this operation as loop runs this sequentially and might take a long time to finish. The operation can be parallelized to reduce the execution time.\n",
    "\n",
    "\n",
    "Each method is suitable for certain types of problems.\n",
    "\n",
    "**Multithreading**: For I/O operations, API calls - reading hundreds of files, making large number of API calls.\n",
    "\n",
    "**Multiprocessing**: For CPU intensive operations - Large math/statistical operations including training large number of ML models.\n",
    "\n",
    "**Distributed processing**: Same as multiprocessing, but when your operations are too long.\n",
    "\n",
    "\n",
    "**Note: Some of the concepts in the notebook is oversimplified for ease of explanation. Please refer the additonal materials to get deeper understanding of the concepts.**\n",
    "\n",
    "[Multithreading vs. Multiprocessing in Python\n",
    "](https://towardsdatascience.com/multithreading-vs-multiprocessing-in-python-3afeb73e105f)\n",
    "\n",
    "[What Is Distributed Computing?\n",
    "](https://hazelcast.com/glossary/distributed-computing/#:~:text=Distributed%20computing%20(or%20distributed%20processing,and%20to%20coordinate%20processing%20power.)\n",
    "\n",
    "[Apache Spark: A Conceptual Orientation](https://towardsdatascience.com/apache-spark-a-conceptual-orientation-e326f8c57a64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1f887-b989-4379-9417-cc987f17ffaa",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f4372a-15b9-4d42-9d10-c65e59902058",
   "metadata": {},
   "source": [
    "The notebook uses a python module `joblib` for parallelizing operations. `joblib` supports all three types of parallelization with a minor code change. The syntax for using joblib is relatively simple and it comes with optmizations for numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25288ec-2fd6-45e8-8362-e2231358f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib==1.1.0 joblibspark==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaccec8e-dab6-45b4-b376-06077d18ff73",
   "metadata": {},
   "source": [
    "Lets take a simple sequential code involving large number of operations and see how you can convert the code to use joblib.  The following is a list comprehesion in Python to find the square root of first 10K numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f00f3c2-1900-419c-abe9-8ee05ba8f502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.98999949994999, 99.99499987499375]\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "results = [sqrt(i) for i in range(10000)]\n",
    "\n",
    "print(results[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11a984-6d99-4898-86ef-064574a15faa",
   "metadata": {},
   "source": [
    "Lets convert this code to use joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5609bbb3-5548-4ab5-85bb-29864c7ebb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.98999949994999, 99.99499987499375]\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "results = Parallel()(delayed(sqrt)(i) for i in range(10000))\n",
    "\n",
    "print(results[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa1738-9165-459e-8ef0-8a3502d3f59b",
   "metadata": {},
   "source": [
    "All we did was wrapping the sqrt function with `Parallel` and `delayed` functions of `joblib`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f04a14-71be-4f9f-9f16-1617ffd9028a",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "Multiprocessing is the technique using which you execute your operations using a seperate dedicated Python process. By default your application runs within a single process. Each Python process uses a CPU in the machine. By using multiple processes you're able to use all the CPUs in the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1026ee7-5ccc-4f2a-9195-a1eaca99ddc8",
   "metadata": {},
   "source": [
    "Let's generate some dummy data for training some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c9db7d-5b98-4949-ad0d-34c56c8a000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_size = 1000000\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=data_size, n_features=10, n_redundant=0)\n",
    "df = pd.DataFrame(data=X)\n",
    "df[\"target\"] = y\n",
    "groups = np.random.choice(1000, size=data_size)\n",
    "df[\"group\"] = groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdce4df-c615-4513-b1e4-963a70a446a3",
   "metadata": {},
   "source": [
    "The `train_model` function accepts a pandas Dataframe input and trains a model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7e0c5c-6581-40c9-b45e-bbe4e84d21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_model(data: pd.DataFrame) -> RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Trains an ML model for with the input data\n",
    "    \"\"\"\n",
    "    X = data.drop([\"target\", \"group\"], axis=1)\n",
    "    y = data[\"target\"]\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1490ed7-72ca-42f2-945a-be4c5ebb2dec",
   "metadata": {},
   "source": [
    "Let's train a model for each group of data we've in the source data. Here the models are trained sequentially without any parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f997f83-8f01-4766-b9b2-98d588cba945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 20s, sys: 1.68 s, total: 4min 21s\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = [train_model(group) for _, group in df.groupby(\"group\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7fc49-d6ea-426d-8b3b-98bc6aff8b68",
   "metadata": {},
   "source": [
    "The entire training process took 1 min 40s. Now let's try it using multiprocessing. Notice the `prefer=processes`, this is the parameter that instructs joblib to use `multiprocessing`. `n_jobs=-2` means it should use all the cpus in the system except one (so that rest of system processes can run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b93270-dd4c-4786-9765-eaaf4492208e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 2.01 s, total: 12.9 s\n",
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "models = Parallel(n_jobs=-2, prefer=\"processes\")(delayed(train_model)(group) for _, group in df.groupby(\"group\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4095f5-0b27-4240-8005-87ffd5a4459c",
   "metadata": {},
   "source": [
    "The operation finished under a minute!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75849dd8-9d4f-482c-82a7-fa0d8b80f09c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distributed processing\n",
    "\n",
    "Multiprocessing uses all the CPUs in a single machine to parallelize workloads. Distributed processing uses multiple machines to parallelize the workloads to get even better performance. Distributed processing in joblib is implemented with the help of Spark.\n",
    "\n",
    "**Note: Distributed processing comes with a considerable overhead. Unless your operations are too slow (execution time over an hour) it shouldn't be used. Using it for short workloads would increase the execution time**\n",
    "\n",
    "Create a Spark session session. Here the `spark.kubernetes.container.image` is a Spark executor image with scikit-learn built in. Use the correct image based on the Spark version you're using:\n",
    "\n",
    "* `3.1.2`: 555157090578.dkr.ecr.us-east-1.amazonaws.com/datascience/mlops/jupyterhub/spark-executor-jupyter:scikit-learn-3-1-2\n",
    "* `3.2.0`: 555157090578.dkr.ecr.us-east-1.amazonaws.com/datascience/mlops/jupyterhub/spark-executor-jupyter:scikit-learn-3-2-0\n",
    "\n",
    "**Warning**: These images are built for just this example code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbf7112-85c9-4140-8c7c-531be2018c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/05/12 06:32:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/12 06:32:21 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "22/05/12 06:32:23 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, avg, col\n",
    "\n",
    "conf = SparkConf()  # create the configuration\n",
    "conf.set(\n",
    "    \"spark.kubernetes.container.image\",\n",
    "    \"555157090578.dkr.ecr.us-east-1.amazonaws.com/datascience/mlops/jupyterhub/spark-executor-jupyter:scikit-learn-3-1-2\"\n",
    ")\n",
    "conf.set(\"spark.rpc.message.maxSize\", 1024)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e6af9b-fedc-4cc6-8f8f-79bd6947be63",
   "metadata": {},
   "source": [
    "Register the Spark session with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7911ca-f14d-404d-8de2-5936ff4c0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblibspark import register_spark\n",
    "register_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474385a-3ff3-4f9f-9889-859f8def6b6c",
   "metadata": {},
   "source": [
    "Change the backend to `spark` and set `n_jobs=50` (this is an ideal number based on our Spark platform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f7d110-bc61-4536-9006-a75481b84c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axj1011/env/fitter/lib/python3.9/site-packages/joblibspark/backend.py:107: UserWarning: User-specified n_jobs (50) is greater than the max number of concurrent tasks (3) this cluster can run now.If dynamic allocation is enabled for the cluster, you might see more executors allocated.\n",
      "  warnings.warn(f\"User-specified n_jobs ({n_jobs}) is greater than the max number of \"\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.53 s, sys: 2.13 s, total: 9.66 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "models = Parallel(n_jobs=50, backend=\"spark\")(delayed(train_model)(group) for _, group in df.groupby(\"group\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20be754-4c39-410e-beec-5f064c858f6b",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab4682-aea2-48df-a4cb-242b1d09440c",
   "metadata": {},
   "source": [
    "Let's try a scenario for multithreading. We've to make 1000 REST API calls to retrieve data from an external system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472532c0-3fb7-4503-81d1-a6a56615f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def make_request(url):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    r.raise_for_status()\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cd8ef8-f53b-4ac5-b8c1-60402fe72c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://www.google.com\"] * 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb874466-83c4-4c6f-ad8e-bf8bb43caca8",
   "metadata": {},
   "source": [
    "Let's make the API calls sequentially first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1a7ba8-d6dd-4db9-a7b9-9f7491e02a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.98 s, sys: 286 ms, total: 5.26 s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "responses = [make_request(url) for url in urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872c533-6731-42c6-829d-3195d0e73414",
   "metadata": {},
   "source": [
    "Let's make the same API calls parallely using multithreading. Notice the `prefer=\"threads\"` which instructs joblib to use multithreading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7703f24f-1381-44e4-a3ac-ed265727fa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.12 s, sys: 407 ms, total: 6.53 s\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "responses = Parallel(n_jobs=20, prefer=\"threads\")(delayed(make_request)(url) for url in urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47fa8f-65c2-4eab-ae1e-e3cee49f0bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fitter",
   "language": "python",
   "name": "fitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
