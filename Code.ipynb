{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/ml_works/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O4ExHj5S_7a1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nEjRm6f_7a3",
        "outputId": "862695a0-1d99-4ef3-bce7-59368fb26adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1.1875596046447754 seconds ---\n",
            "(1944, 175)\n",
            "175\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture('acrobacia.mp4')\n",
        "\n",
        "arr = np.empty((0, 1944), int)   #initializing 1944 dimensional array to store 'flattened' color histograms\n",
        "D=dict()   #to store the original frame (array)\n",
        "count=0    #counting the number of frames\n",
        "start_time = time.time()\n",
        "while cap.isOpened():\n",
        "\n",
        "    # Read the video file.\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # If we got frames.\n",
        "    if ret == True:\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #since cv reads frame in bgr order so rearraning to get frames in rgb order\n",
        "        D[count] = frame_rgb   #storing each frame (array) to D , so that we can identify key frames later\n",
        "\n",
        "        #dividing a frame into 3*3 i.e 9 blocks\n",
        "        height, width, channels = frame_rgb.shape\n",
        "\n",
        "        if height % 3 == 0:\n",
        "            h_chunk = int(height/3)\n",
        "        else:\n",
        "            h_chunk = int(height/3) + 1\n",
        "\n",
        "        if width % 3 == 0:\n",
        "            w_chunk = int(width/3)\n",
        "        else:\n",
        "            w_chunk = int(width/3) + 1\n",
        "\n",
        "        h=0\n",
        "        w= 0\n",
        "        feature_vector = []\n",
        "        for a in range(1,4):\n",
        "            h_window = h_chunk*a\n",
        "            for b in range(1,4):\n",
        "                frame = frame_rgb[h : h_window, w : w_chunk*b , :]\n",
        "                hist = cv2.calcHist(frame, [0, 1, 2], None, [6, 6, 6], [0, 256, 0, 256, 0, 256])#finding histograms for each block\n",
        "                hist1= hist.flatten()  #flatten the hist to one-dimensinal vector\n",
        "                feature_vector += list(hist1)\n",
        "                w = w_chunk*b\n",
        "\n",
        "            h = h_chunk*a\n",
        "            w= 0\n",
        "\n",
        "\n",
        "        arr =np.vstack((arr, feature_vector )) #appending each one-dimensinal vector to generate N*M matrix (where N is number of frames\n",
        "          #and M is 1944)\n",
        "        count+=1\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "final_arr = arr.transpose() #transposing so that i will have all frames in columns i.e M*N dimensional matrix\n",
        "#where M is 1944 and N is number of frames\n",
        "print(final_arr.shape)\n",
        "print(count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IiYa4ify_7a4"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csc_matrix\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "A = csc_matrix(final_arr, dtype=float)\n",
        "\n",
        "#top 63 singular values from 76082 to 508\n",
        "u, s, vt = svds(A, k = 63)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCQeWEsm_7a4",
        "outputId": "49fe697f-5fd2-4597-e0e7-fe7144896c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1944, 63) (63,) (63, 175)\n"
          ]
        }
      ],
      "source": [
        "print(u.shape, s.shape, vt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjLZPS0T_7a4",
        "outputId": "ab0dc3b7-e32a-44c9-f18a-9f76ca46bb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[36.964481774391714, 37.64292845439624, 39.948783146571664, 40.569181384919936, 41.51854381643641, 43.534303646152736, 44.21722836668663, 44.827854465024174, 46.36469099409334, 48.43707247707638, 48.62758139843689, 49.528962971911945, 50.881632594188645, 51.466201085830996, 56.18144200370299, 57.712071405545444, 59.394155849908344, 59.9624402215706, 63.22253574084806, 64.47490317401589, 66.45283696147622, 69.49772584451286, 72.79134236185574, 77.09174904831859, 80.69041031431787, 81.52621781505488, 85.55315145559342, 87.37987625539621, 89.57980825796913, 93.43868809381513, 97.5059284801196, 101.70258346138166, 110.67927488524272, 111.76909313641966, 114.32388009546156, 124.24309906968178, 131.14643580128845, 140.24428772377584, 140.9998429536647, 149.99617490103233, 154.22723406222494, 163.46581316571258, 166.51181495169783, 184.49746107353843, 199.95351836683332, 219.61002018491894, 229.06691241576948, 263.0433979386534, 278.0013634519751, 292.80171546658, 310.2507215269358, 337.1275963148593, 359.5173469726831, 404.69736275406433, 483.92460926430186, 509.603110587801, 553.2423600959297, 642.9172319260861, 890.2669550193806, 1025.903167587921, 1414.032007075723, 2649.4896351896828, 19318.996810949684]\n"
          ]
        }
      ],
      "source": [
        "print(list(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCUdlcZO_7a5",
        "outputId": "d8eb3ea6-5fae-470e-b79b-57640af7d0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(175, 63)\n"
          ]
        }
      ],
      "source": [
        "v1_t = vt.transpose()\n",
        "\n",
        "projections = v1_t @ np.diag(s) #the column vectors i.e the frame histogram data has been projected onto the orthonormal basis\n",
        "#formed by vectors of the left singular matrix u .The coordinates of the frames in this space are given by v1_t @ np.diag(s)\n",
        "#So we can see that , now we need only 63 dimensions to represent each column/frame\n",
        "print(projections.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TXilm58G_7a5"
      },
      "outputs": [],
      "source": [
        "#dynamic clustering of projected frame histograms to find which all frames are similar i.e make shots\n",
        "f=projections\n",
        "C = dict() #to store frames in respective cluster\n",
        "for i in range(f.shape[0]):\n",
        "    C[i] = np.empty((0,63), int)\n",
        "\n",
        "#adding first two projected frames in first cluster i.e Initializaton\n",
        "C[0] = np.vstack((C[0], f[0]))\n",
        "C[0] = np.vstack((C[0], f[1]))\n",
        "\n",
        "E = dict() #to store centroids of each cluster\n",
        "for i in range(projections.shape[0]):\n",
        "    E[i] = np.empty((0,63), int)\n",
        "\n",
        "E[0] = np.mean(C[0], axis=0) #finding centroid of C[0] cluster\n",
        "\n",
        "count = 0\n",
        "for i in range(2,f.shape[0]):\n",
        "    similarity = np.dot(f[i], E[count])/( (np.dot(f[i],f[i]) **.5) * (np.dot(E[count], E[count]) ** .5)) #cosine similarity\n",
        "    #this metric is used to quantify how similar is one vector to other. The maximum value is 1 which indicates they are same\n",
        "    #and if the value is 0 which indicates they are orthogonal nothing is common between them.\n",
        "    #Here we want to find similarity between each projected frame and last cluster formed chronologically.\n",
        "\n",
        "\n",
        "    if similarity < 0.9: #if the projected frame and last cluster formed  are not similar upto 0.9 cosine value then\n",
        "                         #we assign this data point to newly created cluster and find centroid\n",
        "                         #We checked other thresholds also like 0.85, 0.875, 0.95, 0.98\n",
        "                        #but 0.9 looks okay because as we go below then we get many key-frames for similar event and\n",
        "                        #as we go above we have lesser number of key-frames thus missed some events. So, 0.9 seems optimal.\n",
        "\n",
        "        count+=1\n",
        "        C[count] = np.vstack((C[count], f[i]))\n",
        "        E[count] = np.mean(C[count], axis=0)\n",
        "    else:  #if they are similar then assign this data point to last cluster formed and update the centroid of the cluster\n",
        "        C[count] = np.vstack((C[count], f[i]))\n",
        "        E[count] = np.mean(C[count], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nxhVrpU-_7a5"
      },
      "outputs": [],
      "source": [
        "b = []  #find the number of data points in each cluster formed.\n",
        "\n",
        "#We can assume that sparse clusters indicates\n",
        "#transition between shots so we will ignore these frames which lies in such clusters and wherever the clusters are densely populated indicates they form shots\n",
        "#and we can take the last element of these shots to summarise that particular shot\n",
        "\n",
        "for i in range(f.shape[0]):\n",
        "    b.append(C[i].shape[0])\n",
        "\n",
        "last = b.index(0)  #where we find 0 in b indicates that all required clusters have been formed , so we can delete these from C\n",
        "b1=b[:last ] #The size of each cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DcXv0D__7a6",
        "outputId": "4551d683-7a02-4656-dbb1-b0a702ba3fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "res = [idx for idx, val in enumerate(b1) if val >= 25] #so i am assuming any dense cluster with atleast 25 frames is eligible to\n",
        "#make shot.\n",
        "print(len(res)) #so total 25 shots with 46 (71-25) cuts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CXObbobS_7a6"
      },
      "outputs": [],
      "source": [
        "GG = C #copying the elements of C to GG, the purpose of  the below code is to label each cluster so later\n",
        "#it would be easier to identify frames in each cluster\n",
        "for i in range(last):\n",
        "    p1= np.repeat(i, b1[i]).reshape(b1[i],1)\n",
        "    GG[i] = np.hstack((GG[i],p1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V7Qc3L-v_7a6"
      },
      "outputs": [],
      "source": [
        "#the purpose of the below code is to append each cluster to get multidimensional array of dimension N*64, N is number of frames\n",
        "F=  np.empty((0,64), int)\n",
        "for i in range(last):\n",
        "    F = np.vstack((F,GG[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxtDCw_H_7a6",
        "outputId": "1904da06-1aed-4b2c-bb34-f409e573fbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31', 'v32', 'v33', 'v34', 'v35', 'v36', 'v37', 'v38', 'v39', 'v40', 'v41', 'v42', 'v43', 'v44', 'v45', 'v46', 'v47', 'v48', 'v49', 'v50', 'v51', 'v52', 'v53', 'v54', 'v55', 'v56', 'v57', 'v58', 'v59', 'v60', 'v61', 'v62', 'v63', 'v64']\n"
          ]
        }
      ],
      "source": [
        "#converting F (multidimensional array)  to dataframe\n",
        "\n",
        "colnames = []\n",
        "for i in range(1, 65):\n",
        "    col_name = \"v\" + str(i)\n",
        "    colnames+= [col_name]\n",
        "print(colnames)\n",
        "\n",
        "df = pd.DataFrame(F, columns= colnames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UXHL5Z6T_7a6"
      },
      "outputs": [],
      "source": [
        "df['v64']= df['v64'].astype(int)  #converting the cluster level from float type to integer type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SvDlzd_f_7a6"
      },
      "outputs": [],
      "source": [
        "df1 =  df[df.v64.isin(res)]   #filter only those frames which are eligible to be a part of shot or filter those frames who are\n",
        "#part of required clusters that have more than 25 frames in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0vIeNgH9_7a6"
      },
      "outputs": [],
      "source": [
        "new = df1.groupby('v64').tail(1)['v64'] #For each cluster /group take its last element which summarize the shot i.e key-frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kT8rgVOD_7a7"
      },
      "outputs": [],
      "source": [
        "\n",
        "new1 = new.index #finding key-frames (frame number so that we can go back get the original picture)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AnMCA3YN_7a7"
      },
      "outputs": [],
      "source": [
        "#output the frames in png format\n",
        "for c in new1:\n",
        "    frame_rgb1 = cv2.cvtColor(D[c], cv2.COLOR_RGB2BGR) #since cv consider image in BGR order\n",
        "    frame_num_chr = str(c)\n",
        "    file_name = 'frame'+ frame_num_chr +'.png'\n",
        "    cv2.imwrite(file_name, frame_rgb1)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KpEOQUjQ_7a7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}