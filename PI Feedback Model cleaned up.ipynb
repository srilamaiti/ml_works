{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1b9a231-bee4-4003-b9d5-fa3e5a8556bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a8fb92f-64f0-47fd-b53d-31593ed31fc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, precision_recall_curve, recall_score, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from pyspark.sql.functions import regexp_replace, col, datediff, lit, expr, date_format, cast, row_number, sum, count, min,max, when, desc, ceil, log\n",
    "from pyspark.ml.stat import Correlation\n",
    "from numpy import argmax\n",
    "from pyspark.sql import Window\n",
    "from functools import reduce\n",
    "from operator import concat\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import math\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sfUtils = sc._jvm.net.snowflake.spark.snowflake.Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "333bc80c-be5d-44bb-8512-8162a5870eb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/mgal254@safeway.com/mg_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7348672-fbe0-4692-a69a-a1e3446bc974",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q1 = \"\"\"\n",
    "          create or replace table edm_features_prd.scratch_ds.pi_validation_final_mg as (\n",
    "          select base.*exclude(cal_date,upc,total_pi,primary_shelf_pi,secondary_shelf_pi,backroom_pi),\n",
    "          regexp_replace(backroom_pi,'O|o',0) as backroom_pi,\n",
    "          regexp_replace(primary_shelf_pi,'O|o',0) as primary_shelf_pi,\n",
    "          regexp_replace(secondary_shelf_pi,'O|o',0) as secondary_shelf_pi,\n",
    "          regexp_replace(total_pi,'O|o',0) as total_pi,\n",
    "          upc as upc_nbr,to_date(replace(cal_date,'Z ','')) as cal_date, u.smic_category_id\n",
    "          from EDM_FEATURES_PRD.SCRATCH_DS.STORE_PI_VALIDATION base\n",
    "          left join edm_views_prd.dw_views.d1_upc u\n",
    "          on upc = upc_nbr\n",
    "          )\n",
    "\"\"\"\n",
    "sfUtils.runQuery(ITDSreadOptions, q1)\n",
    "\n",
    "q2 = \"\"\"UPDATE edm_features_prd.scratch_ds.pi_validation_final_mg \n",
    "        SET total_pi = NULLIF(total_pi, 'NaN'),\n",
    "        primary_shelf_pi = NULLIF(primary_shelf_pi, 'NaN'),\n",
    "        secondary_shelf_pi = NULLIF(secondary_shelf_pi, 'NaN'),\n",
    "        backroom_pi = NULLIF(backroom_pi, 'NaN')\n",
    "     \"\"\"\n",
    "sfUtils.runQuery(ITDSreadOptions, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dbf41b0-3f7d-4ad2-a072-c3491e25e39e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "store_fdbk_table = 'edm_features_prd.scratch_ds.pi_validation_final_mg'\n",
    "\n",
    "cal_date_q = f\"\"\"\n",
    "                select distinct to_date(cal_date) as cal_date, store_id, smic_category_id\n",
    "                from {store_fdbk_table}\n",
    "\"\"\" \n",
    "cal_dt_df = read_snowflake(edm_env,cal_date_q,\"regular\")\n",
    "cal_dt_list = cal_dt_df.select(col(\"cal_date\").cast(\"string\")).distinct().rdd.map(lambda row : row[0]).collect()\n",
    "store_list = cal_dt_df.select(col(\"store_id\").cast(\"string\")).distinct().rdd.map(lambda row : row[0]).collect()\n",
    "cat_list = cal_dt_df.select(col(\"smic_category_id\")).distinct().rdd.map(lambda row : row[0]).collect()\n",
    "\n",
    "store_list_str = \",\".join(store_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45284243-f4ae-42c7-b281-6034a76c7586",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_constant = '0321'\n",
    "cal_dt = '2023-03-21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd7e24ee-4025-4c60-9be2-9b9c0df974cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q1 = f\"call edm_features_prd.scratch_ds.s1_pi_ml_features({table_constant} VARCHAR);\"\n",
    "sfUtils.runQuery(ITDSreadOptions,q1)\n",
    "\n",
    "q2 = f\"call edm_features_prd.scratch_ds.s2_pi_ml_features({cal_dt} VARCHAR, {table_constant} VARCHAR);\"\n",
    "sfUtils.runQuery(ITDSreadOptions,q2)\n",
    "\n",
    "q3 = f\"call edm_features_prd.scratch_ds.pi_ml_input({table_constant} VARCHAR);\"\n",
    "sfUtils.runQuery(ITDSreadOptions,q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d401266-3e59-4d8a-8d5c-c400e375e443",
     "showTitle": true,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q = f\"\"\"\n",
    "      select * from edm_features_prd.scratch_ds.pi_ml_model_input_final_0327\n",
    "\"\"\"\n",
    "\n",
    "df_all = read_snowflake(edm_env, q,\"regular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adf3da2a-d618-45c5-a67a-dbc3baaecaca",
     "showTitle": true,
     "title": "Get Presentation Stock from ADLS & join it with base data"
    }
   },
   "outputs": [],
   "source": [
    "ps_query= f\"\"\"\n",
    "             select * \n",
    "             from (\n",
    "             select *,ROW_NUMBER() OVER(PARTITION BY U_CIC_CODE,U_STORE order by LAST_UPDT_TS desc) as rn \n",
    "             from scmrep.jda_inventory_store where cast(U_STORE as int) in ({store_list_str})\n",
    "             ) \n",
    "             where rn=1\n",
    "            \"\"\"\n",
    "ps_df_temp = pd.read_sql(ps_query,get_connector())\n",
    "ps_df = spark.createDataFrame(ps_df_temp)\n",
    "\n",
    "ps_df = ps_df.withColumn(\"U_STORE\", ps_df.U_STORE.cast('int'))\n",
    "df_all_ps = df_all.join(ps_df,((df_all.store_id == ps_df.U_STORE) & (df_all.corporate_item_cd == ps_df.U_CIC_CODE)), how = 'left').select(df_all[\"*\"],ps_df['U_PS_QTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b61e74f-38b5-4ef3-bdef-47866fcc3d80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_all_ps.toPandas()\n",
    "\n",
    "cols = ['TOTAL_PI_CHANGE', 'PI_CHANGES', 'NEG_PI_CHANGES', 'POS_PI_CHANGES',\n",
    "       'PI_START', 'PI_END', 'NET_PI_CHANGE']\n",
    "\n",
    "df[cols] = df[cols].fillna(0)\n",
    "df[cols] = df[cols].apply(pd.to_numeric)\n",
    "\n",
    "df['U_PS_QTY'] = df['U_PS_QTY'].astype('float')\n",
    "df['baseline_onhand'] = df['baseline_onhand'].astype('float')\n",
    "df['baseline_ps_oos'] = df[['baseline_onhand','U_PS_QTY']].apply(lambda x : 1 if x[0] <= x[1] else 0, axis = 1)\n",
    "df['baseline_oos'] = df['baseline_onhand'].apply(lambda x : 1 if x == 0 else 0)\n",
    "\n",
    "df['baseline_diff_pct'] = df['baseline_diff']/df['day_end_on_hand']\n",
    "df['pi_change_pct'] = df['TOTAL_PI_CHANGE']/df['day_end_on_hand']\n",
    "\n",
    "df['oos_res_ps'] = df[['feedback_pi','U_PS_QTY']].apply(lambda x: 1 if x[0] < x[1] else 0, axis = 1)\n",
    "df['oos_alert_ps'] = df[['baseline_onhand','U_PS_QTY']].apply(lambda x: 1 if x[0] < x[1] else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f951704c-2839-4fa9-b805-a29d8c9b21ad",
     "showTitle": true,
     "title": "Modeling - yet to be cleaned"
    }
   },
   "outputs": [],
   "source": [
    "df.txn_dte = pd.to_datetime(df.txn_dte)\n",
    "df['week_of_year'] = df.txn_dte.dt.weekofyear\n",
    "\n",
    "df['txn_dt_str'] = pd.to_datetime(df.txn_dte).dt.strftime('%Y-%m-%d')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_sub = df[['sold_more_than_shipped','baseline_ps_oos','n_sub_sale_pct','oos_res','oos_alert','oos_alert_ps','oos_res_ps','n_dst_sale_pct','n_cat_sale_pct','n_cons_zero_sale_days','item_velocity','oos_final','pi_change_pct','week_of_year','dayofwk','txn_dt_str','feedback_pi']]\n",
    "df_sub.dropna(inplace = True)\n",
    "print(df_sub.shape)\n",
    "df = df.iloc[df_sub.index]\n",
    "\n",
    "df_sub[['sold_more_than_shipped','baseline_ps_oos','oos_alert','n_cons_zero_sale_days','oos_final','week_of_year']] = df_sub[['sold_more_than_shipped','baseline_ps_oos','oos_alert','n_cons_zero_sale_days','oos_final','week_of_year']].apply(pd.to_numeric)\n",
    "df_sub[['n_sub_sale_pct','n_dst_sale_pct','n_cat_sale_pct','item_velocity','pi_change_pct']] = df_sub[['n_sub_sale_pct','n_dst_sale_pct','n_cat_sale_pct','item_velocity','pi_change_pct']].astype('float')\n",
    "\n",
    "df_train = df_sub.loc[(df_sub.txn_dt_str <= '2023-03-08')]\n",
    "df_test = df_sub.loc[(df_sub.txn_dt_str > '2023-03-08') & (df_sub.txn_dt_str < '2023-03-21') & (~df_sub.feedback_pi.isna())]\n",
    "\n",
    "# X_train = df_train[['sold_more_than_shipped','baseline_ps_oos','n_sub_sale_pct','n_dst_sale_pct','pi_change_pct','week_of_year']]\n",
    "X_train = df_train[['sold_more_than_shipped','baseline_ps_oos','n_sub_sale_pct','n_dst_sale_pct']]\n",
    "# X_train = df_train[['oos_alert']]\n",
    "y_train = df_train['oos_res']\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "# X_test = df_test[['sold_more_than_shipped','baseline_ps_oos','n_sub_sale_pct','n_dst_sale_pct','pi_change_pct','week_of_year']]\n",
    "X_test = df_test[['sold_more_than_shipped','baseline_ps_oos','n_sub_sale_pct','n_dst_sale_pct']]\n",
    "# X_test = df_test[['oos_alert']]\n",
    "y_test = df_test['oos_res']\n",
    "y_test = y_test.astype('int')\n",
    "test_index = X_test.index\n",
    "\n",
    "clf = LogisticRegression(max_iter = 1500, random_state = 26, class_weight = 'balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# # Predict the probabilities of the binary outcome\n",
    "y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test,y_probs)\n",
    "f1score = (2 * precision * recall) / (precision + recall)\n",
    "ix = argmax(f1score)\n",
    "\n",
    "y_pred = (y_probs >= thresholds[ix]).astype('int')\n",
    "\n",
    "df_pred_prob = pd.DataFrame(y_probs)\n",
    "df_pred_prob.set_index(test_index, inplace = True)\n",
    "df_y_test = pd.DataFrame(y_test)\n",
    "df_y_test.set_index(test_index, inplace = True)\n",
    "df_final = pd.concat([df.iloc[test_index],df_pred_prob], axis = 1)\n",
    "l = list(df.columns)\n",
    "l.extend(['pred_prob'])\n",
    "df_final.columns = l\n",
    "df_final['oos_pred'] = df_final['pred_prob'].apply(lambda x : (x >= thresholds[ix]).astype('int'))\n",
    "\n",
    "# Evaluate the performance of the model using the f1 score\n",
    "score = roc_auc_score(y_test, y_probs)\n",
    "acc_score = accuracy_score(y_test,df_final.oos_pred)\n",
    "precision = precision_score(y_test,df_final.oos_pred)\n",
    "recall = recall_score(y_test,df_final.oos_pred)\n",
    "precision_test = precision_score(y_test,y_pred)\n",
    "f1_scr = f1_score(y_test,df_final.oos_pred)\n",
    "print(\"f1 score \", f1_scr)\n",
    "print(\"precision\", precision)\n",
    "print(\"recall\", recall)\n",
    "print(\"accuracy\", acc_score)\n",
    "print(\"threshold\",thresholds[ix])\n",
    "#   df_metrics = pd.DataFrame({'store_id' : store,'smic_category_id' : smic_category_id, 'precision' : precision, 'f1_score' : f1_scr}, index = [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d67a4de8-fa03-4304-981d-b3a52d9ac27c",
     "showTitle": true,
     "title": "Predict oos on new data"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_sub.loc[df_sub.txn_dt_str == {cal_dt}]\n",
    "X_test = df_test[['sold_more_than_shipped','baseline_ps_oos','n_sub_sale_pct','n_dst_sale_pct']]\n",
    "test_index = X_test.index\n",
    "\n",
    "\n",
    "# # Predict the probabilities of the binary outcome\n",
    "y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_probs >= thresholds[ix]).astype('int')\n",
    "\n",
    "df_pred_prob = pd.DataFrame(y_probs)\n",
    "df_pred_prob.set_index(test_index, inplace = True)\n",
    "df_final = pd.concat([df_test.iloc[test_index],df_pred_prob], axis = 1)\n",
    "l = list(df_test.columns)\n",
    "l.extend(['pred_prob'])\n",
    "df_final.columns = l\n",
    "df_final['oos_pred'] = df_final['pred_prob'].apply(lambda x : (x >= thresholds[ix]).astype('int'))\n",
    "df_output = df_final.loc[df_final.oos_pred == 1]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "PI Feedback Model cleaned up",
   "notebookOrigID": 807721772415392,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
